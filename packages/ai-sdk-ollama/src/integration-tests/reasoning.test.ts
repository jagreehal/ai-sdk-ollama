import { describe, it, expect } from 'vitest';
import { generateText, streamText } from 'ai';
import { ollama } from '../index';

// Integration test for reasoning capabilities
describe('Reasoning Integration Tests', { timeout: 120_000 }, () => {
  it('should generate text with reasoning enabled', async () => {
    try {
      const result = await generateText({
        model: ollama('deepseek-r1:7b', { reasoning: true }),
        prompt: 'Calculate: 12 + 8 = ?',
        maxOutputTokens: 500,
        temperature: 0.1,
      });

      expect(result.text).toBeTruthy();
      expect(typeof result.text).toBe('string');

      // DeepSeek-R1 includes reasoning in <think> tags
      expect(result.text).toMatch(/<think>/i);

      // Should attempt to solve the math problem (flexible check)
      const hasRelevantContent =
        result.text.toLowerCase().includes('12') ||
        result.text.toLowerCase().includes('8') ||
        result.text.toLowerCase().includes('add') ||
        result.text.includes('20') ||
        result.text.includes('twenty');
      expect(hasRelevantContent).toBe(true);
    } catch (error) {
      // Skip test if model not available
      if (
        error instanceof Error &&
        error.message?.includes('model not found')
      ) {
        console.log('Skipping test: deepseek-r1:7b not available');
        return;
      }
      throw error;
    }
  });

  it('should not show reasoning when disabled', async () => {
    try {
      const result = await generateText({
        model: ollama('deepseek-r1:7b', { reasoning: false }),
        prompt: 'Calculate: 12 + 8 = ?',
        maxOutputTokens: 300,
        temperature: 0.1,
      });

      expect(result.text).toBeTruthy();

      // Should produce some output for the math problem
      expect(result.text.length).toBeGreaterThan(0);

      // Count think tags - when reasoning is disabled, should typically have fewer
      const thinkTagCount = (result.text.match(/<think>/g) || []).length;
      // Flexible: just verify it produces valid output
      expect(thinkTagCount).toBeGreaterThanOrEqual(0);
    } catch (error) {
      if (
        error instanceof Error &&
        error.message?.includes('model not found')
      ) {
        console.log('Skipping test: deepseek-r1:7b not available');
        return;
      }
      throw error;
    }
  });

  it('should handle reasoning with complex math problem', async () => {
    try {
      const result = await generateText({
        model: ollama('deepseek-r1:7b', { reasoning: true }),
        prompt:
          'If a train travels 60 km/h for 2 hours, how far does it go? Show your work.',
        maxOutputTokens: 300,
        temperature: 0.1,
      });

      expect(result.text).toBeTruthy();

      // Should contain reasoning about the problem
      const hasReasoningIndicators =
        result.text.toLowerCase().includes('hour') ||
        result.text.toLowerCase().includes('km') ||
        result.text.toLowerCase().includes('speed') ||
        result.text.toLowerCase().includes('distance') ||
        result.text.includes('<think>') ||
        result.text.toLowerCase().includes('travel');

      expect(hasReasoningIndicators).toBe(true);
    } catch (error) {
      if (
        error instanceof Error &&
        error.message?.includes('model not found')
      ) {
        console.log('Skipping test: deepseek-r1:7b not available');
        return;
      }
      throw error;
    }
  });

  it('should stream text with reasoning enabled', async () => {
    try {
      const { textStream } = await streamText({
        model: ollama('deepseek-r1:7b', { reasoning: true }),
        prompt: 'What is 5 + 3?',
        maxOutputTokens: 150,
        temperature: 0.1,
      });

      let fullText = '';
      for await (const chunk of textStream) {
        fullText += chunk;
      }

      expect(fullText).toBeTruthy();

      // Should produce output for the simple math problem
      expect(fullText.length).toBeGreaterThan(0);
    } catch (error) {
      if (
        error instanceof Error &&
        error.message?.includes('model not found')
      ) {
        console.log('Skipping test: deepseek-r1:7b not available');
        return;
      }
      throw error;
    }
  });

  it('should handle reasoning with logic puzzles', async () => {
    try {
      const result = await generateText({
        model: ollama('deepseek-r1:7b', { reasoning: true }),
        prompt:
          'If all roses are flowers and some flowers are red, can we conclude that some roses are red? Explain your reasoning.',
        maxOutputTokens: 400,
        temperature: 0.2,
      });

      expect(result.text).toBeTruthy();

      // Should contain reasoning about the logic puzzle
      const hasLogicalContent =
        result.text.toLowerCase().includes('roses') ||
        result.text.toLowerCase().includes('flowers') ||
        result.text.toLowerCase().includes('red') ||
        result.text.includes('<think>') ||
        result.text.toLowerCase().includes('conclude');

      expect(hasLogicalContent).toBe(true);
    } catch (error) {
      if (
        error instanceof Error &&
        error.message?.includes('model not found')
      ) {
        console.log('Skipping test: deepseek-r1:7b not available');
        return;
      }
      throw error;
    }
  });

  it('should handle reasoning with code verification', async () => {
    try {
      const result = await generateText({
        model: ollama('deepseek-r1:7b', { reasoning: true }),
        prompt: `Is this function correct for checking if a number is even?
function isEven(n) {
  return n % 2 === 0;
}
Test with n=4 and n=7.`,
        maxOutputTokens: 500,
        temperature: 0.1,
      });

      expect(result.text).toBeTruthy();

      // Should analyze the code (flexible check)
      const hasCodeAnalysis =
        result.text.toLowerCase().includes('function') ||
        result.text.toLowerCase().includes('even') ||
        result.text.includes('4') ||
        result.text.includes('7') ||
        result.text.includes('<think>') ||
        result.text.includes('%');

      expect(hasCodeAnalysis).toBe(true);
    } catch (error) {
      if (
        error instanceof Error &&
        error.message?.includes('model not found')
      ) {
        console.log('Skipping test: deepseek-r1:7b not available');
        return;
      }
      throw error;
    }
  });

  it('should compare reasoning vs non-reasoning output length', async () => {
    try {
      const prompt = 'Solve: 15 Ã— 4 = ?';

      // With reasoning
      const withReasoning = await generateText({
        model: ollama('deepseek-r1:7b', { reasoning: true }),
        prompt,
        maxOutputTokens: 300,
        temperature: 0.1,
      });

      // Without reasoning
      const withoutReasoning = await generateText({
        model: ollama('deepseek-r1:7b', { reasoning: false }),
        prompt,
        maxOutputTokens: 300,
        temperature: 0.1,
      });

      expect(withReasoning.text).toBeTruthy();
      expect(withoutReasoning.text).toBeTruthy();

      // Both should produce valid output for the multiplication
      // At least attempt to solve (flexible since model output varies)
      expect(withReasoning.text.length).toBeGreaterThan(0);
      expect(withoutReasoning.text.length).toBeGreaterThan(0);

      // Reasoning output is typically longer due to thinking process
      // This is a soft check as it may vary
      console.log('With reasoning length:', withReasoning.text.length);
      console.log('Without reasoning length:', withoutReasoning.text.length);
    } catch (error) {
      if (
        error instanceof Error &&
        error.message?.includes('model not found')
      ) {
        console.log('Skipping test: deepseek-r1:7b not available');
        return;
      }
      throw error;
    }
  });
});
